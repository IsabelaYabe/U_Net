{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import torch\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessDataset(Dataset):\n",
    "    def __init__(self, dir_dataset, df_labels, dir_new_dataset, set_type=\"train\", with_brightness_contrast=True, var_gaussian=10, amount = 0.02, prob_gen=0.4, partition=3): \n",
    "        self.with_brightness_contrast = with_brightness_contrast\n",
    "        self.var_gaussian = var_gaussian\n",
    "        self.amount = amount\n",
    "        self.dir_dataset = dir_dataset\n",
    "        self.prob_gen = prob_gen\n",
    "        self.set_type = set_type\n",
    "        self.dir_new_dataset = dir_new_dataset\n",
    "        self.partition = partition\n",
    "        self.rgb_to_index, self.index_to_label = self.dict_labels(df_labels)\n",
    "        self.df_labels = df_labels\n",
    "        self.dim_images = None\n",
    "        self.num_images = None\n",
    "        self.image_list = [] \n",
    "        self.label_list = [] \n",
    "        self.num_classes = len(self.df_labels)\n",
    "        self.load_images_from_folder()\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Carregar a imagem e o rótulo baseado no índice `idx`\n",
    "        img_path = self.image_list[idx]\n",
    "        lbl_path = self.label_list[idx]\n",
    "\n",
    "        # Carregar a imagem e o rótulo do disco\n",
    "        img = cv2.imread(img_path)\n",
    "        lbl = cv2.imread(lbl_path)\n",
    "\n",
    "        # Normalizar a imagem (opcional)\n",
    "        img = img / 255.0\n",
    "\n",
    "        # Converter os dados para tensores\n",
    "        img = torch.tensor(img, dtype=torch.float32).permute(2, 0, 1)  # De (H, W, C) para (C, H, W)\n",
    "        lbl = torch.tensor(lbl, dtype=torch.long)\n",
    "\n",
    "        return img, lbl\n",
    "\n",
    "    def create_or_reset_directory(self):\n",
    "        new_dir_img = os.path.join(self.dir_new_dataset, self.set_type)\n",
    "        new_dir_lbl = os.path.join(self.dir_new_dataset, f\"{self.set_type}_labels\")\n",
    "        \n",
    "        # Verificar se o diretório de imagens já existe; se não, criar\n",
    "        if not os.path.exists(new_dir_img):\n",
    "            os.makedirs(new_dir_img)  # Cria o diretório se não existir\n",
    "        \n",
    "        # Verificar se o diretório de rótulos já existe; se não, criar\n",
    "        if not os.path.exists(new_dir_lbl):\n",
    "            os.makedirs(new_dir_lbl)  # Cria o diretório se não existir\n",
    "        \n",
    "    def load_images_from_folder(self):\n",
    "        # Definir os caminhos originais dos datasets\n",
    "        images_dir = os.path.join(self.dir_dataset, self.set_type)\n",
    "        labels_dir = os.path.join(self.dir_dataset, f\"{self.set_type}_labels\")\n",
    "        \n",
    "        dim_images = self.load_images_and_labels(images_dir, labels_dir)\n",
    "        self.dim_images = dim_images\n",
    "            \n",
    "    def load_images_and_labels(self, images_dir, labels_dir):\n",
    "        self.create_or_reset_directory()\n",
    "\n",
    "        # Listar arquivos nos diretórios\n",
    "        image_files = sorted(os.listdir(images_dir))\n",
    "        label_files = sorted(os.listdir(labels_dir))\n",
    "\n",
    "        prob_to_transform = self.prob_gen\n",
    "        img_lbl_files = zip(image_files, label_files)\n",
    "\n",
    "        for img_name, lbl_name in img_lbl_files:\n",
    "            transform_img = random.choices([True, False], weights=[prob_to_transform, 1 - prob_to_transform], k=1)[0]\n",
    "\n",
    "            # Definir caminho para a imagem e rótulo\n",
    "            img_path = os.path.join(images_dir, img_name)\n",
    "            lbl_path = os.path.join(labels_dir, lbl_name)\n",
    "\n",
    "            # Carregar imagem e rótulo\n",
    "            img = cv2.imread(img_path)\n",
    "            lbl = cv2.imread(lbl_path)\n",
    "\n",
    "            # Reduzir a resolução da imagem\n",
    "            img = img[::self.partition, ::self.partition, :]\n",
    "            lbl = lbl[::self.partition, ::self.partition, :]\n",
    "\n",
    "            # Converter de BGR para RGB\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            lbl = cv2.cvtColor(lbl, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Aplicar Gaussian blur\n",
    "            img = cv2.GaussianBlur(img, (3, 3), 0)\n",
    "\n",
    "            # Transformação aleatória\n",
    "            if transform_img:\n",
    "                img_transform = img.copy()\n",
    "                lbl_transform = lbl.copy()\n",
    "                img_transform, lbl_transform, trans = self.apply_random_transformation(img_transform, lbl_transform)\n",
    "\n",
    "                # Salvar imagem e rótulo transformado com sufixo de transformação\n",
    "                transformed_img_name = f\"{img_name}_{trans}.png\"\n",
    "                transformed_lbl_name = f\"{lbl_name}_{trans}.png\"\n",
    "\n",
    "                processed_img_path = os.path.join(self.dir_new_dataset, self.set_type, transformed_img_name)\n",
    "                processed_lbl_path = os.path.join(self.dir_new_dataset, f\"{self.set_type}_labels\", transformed_lbl_name)\n",
    "\n",
    "                # Verifique se o arquivo já existe antes de salvar\n",
    "                if not os.path.exists(processed_img_path):\n",
    "                    cv2.imwrite(processed_img_path, img_transform)\n",
    "                    cv2.imwrite(processed_lbl_path, lbl_transform)\n",
    "\n",
    "                    # Adicionar as imagens e rótulos transformados às listas\n",
    "                    self.image_list.append(processed_img_path)\n",
    "                    self.label_list.append(processed_lbl_path)\n",
    "\n",
    "            # Criar caminho para salvar a imagem transformada\n",
    "            processed_img_path = os.path.join(self.dir_new_dataset, self.set_type, img_name)\n",
    "            processed_lbl_path = os.path.join(self.dir_new_dataset, f\"{self.set_type}_labels\", lbl_name)\n",
    "\n",
    "            cv2.imwrite(processed_img_path, img)\n",
    "            cv2.imwrite(processed_lbl_path, lbl)\n",
    "            \n",
    "            # Adicionar as imagens e rótulos processados às listas\n",
    "            self.image_list.append(processed_img_path)\n",
    "            self.label_list.append(processed_lbl_path)\n",
    "\n",
    "        return img.shape\n",
    "\n",
    "    def apply_random_transformation(self, img, lbl):\n",
    "        if self.with_brightness_contrast:\n",
    "            random_transform = random.randint(0, 9)\n",
    "        else:\n",
    "            random_transform = random.randint(0, 4)\n",
    "        if random_transform == 0:\n",
    "            arg_1, arg_2 = self.augment(img, lbl, \"rotation\")\n",
    "            return arg_1, arg_2, \"rotation\"\n",
    "        elif random_transform == 1:\n",
    "            arg_1, arg_2 = self.augment(img, lbl, \"flip\")\n",
    "            return arg_1, arg_2, \"flip\"\n",
    "        elif random_transform == 2:\n",
    "            arg_1, arg_2 = self.augment(img, lbl, \"flip_rotation\")\n",
    "            return arg_1, arg_2, \"flip_rotation\"\n",
    "        elif random_transform == 3:\n",
    "            arg_1, arg_2 = self.equalize_histogram(img, lbl)\n",
    "            return arg_1, arg_2, \"equalize_histogram\"\n",
    "        elif random_transform == 4:\n",
    "            arg_1, arg_2 = self.add_noise(img, lbl, noise_type=\"gaussian\")\n",
    "            return arg_1, arg_2, \"gaussian_noise\"\n",
    "        elif random_transform == 5:\n",
    "            arg_1, arg_2 = self.add_noise(img, lbl, noise_type=\"salt_pepper\")\n",
    "            return arg_1, arg_2, \"sal_pepper_noise\"\n",
    "        elif random_transform == 6:\n",
    "            arg_1, arg_2 = self.adjust_brightness_contrast(img, lbl, brightness=0, contrast=50)\n",
    "            return arg_1, arg_2, \"b_c_0_50\"\n",
    "        elif random_transform == 7:\n",
    "            arg_1, arg_2 = self.adjust_brightness_contrast(img, lbl, brightness=-10, contrast=30)\n",
    "            return arg_1, arg_2, \"b_c_-10_30\"\n",
    "        elif random_transform == 8:\n",
    "            arg_1, arg_2 = self.adjust_brightness_contrast(img, lbl, brightness=60, contrast=60)\n",
    "            return arg_1, arg_2, \"b_c_60_60\"\n",
    "        else:\n",
    "            arg_1, arg_2 = self.adjust_brightness_contrast(img, lbl, brightness=-20, contrast=0)\n",
    "            return arg_1, arg_2, \"b_c_-20_0\"\n",
    "\n",
    "    def rgb_to_label(self, mask):\n",
    "        unique_colors = np.unique(mask.reshape(-1, mask.shape[2]), axis=0)\n",
    "        label_mask = np.zeros((mask.shape[0], mask.shape[1]), dtype=np.int32)\n",
    "        for color in unique_colors:\n",
    "            color_tuple = tuple(color)\n",
    "            if color_tuple in self.rgb_to_index:\n",
    "                label = self.rgb_to_index[color_tuple]\n",
    "                matches = np.all(mask == color, axis=-1)\n",
    "                label_mask[matches] = label\n",
    "        return label_mask\n",
    "\n",
    "    def dict_labels(self, df_labels):\n",
    "        rgb_to_index = {}\n",
    "        index_to_label = {}\n",
    "        for count, row in df_labels.iterrows():\n",
    "            color = (row['r'], row['g'], row['b'])\n",
    "            label = row['name']\n",
    "            rgb_to_index[color] = count\n",
    "            index_to_label[count] = label\n",
    "        return rgb_to_index, index_to_label\n",
    "\n",
    "    def augment(self, img, lbl, transform):\n",
    "        if transform == \"rotation\":\n",
    "            rotation = cv2.getRotationMatrix2D((img.shape[1] // 2, img.shape[0] // 2), 180, 1)\n",
    "            rotated_image = cv2.warpAffine(img, rotation, (img.shape[1], img.shape[0]))\n",
    "            rotated_label = cv2.warpAffine(lbl, rotation, (lbl.shape[1], lbl.shape[0]), flags=cv2.INTER_NEAREST)\n",
    "            return rotated_image, rotated_label\n",
    "        elif transform == \"flip\":\n",
    "            flipped_image = cv2.flip(img, 1)\n",
    "            flipped_label = cv2.flip(lbl, 1)\n",
    "            return flipped_image, flipped_label\n",
    "        elif transform == \"flip_rotation\":\n",
    "            flipped_image = cv2.flip(img, 0)\n",
    "            flipped_label = cv2.flip(lbl, 0)\n",
    "            return flipped_image, flipped_label\n",
    "        \n",
    "   \n",
    "    def equalize_histogram(self, img, lbl):\n",
    "        img_yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "        img_yuv[:, :, 0] = cv2.equalizeHist(img_yuv[:, :, 0])\n",
    "        img = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2BGR)\n",
    "        return img, lbl\n",
    "        \n",
    "    def adjust_brightness_contrast(self, img, lbl, brightness=0, contrast=0):\n",
    "        img = np.int16(img)\n",
    "        img = img * (contrast / 127 + 1) - contrast + brightness\n",
    "        img = np.clip(img, 0, 255)\n",
    "        img = np.uint8(img)\n",
    "        return img, lbl\n",
    "    \n",
    "    def add_noise(self, img, lbl, noise_type=\"gaussian\"):\n",
    "        if noise_type == \"gaussian\":\n",
    "            mean = 0\n",
    "            var = self.var_gaussian\n",
    "            sigma = var ** 0.5\n",
    "            gauss = np.random.normal(mean, sigma, img.shape)\n",
    "            noisy = img + gauss\n",
    "            noisy = np.clip(noisy, 0, 255)\n",
    "            return noisy, lbl\n",
    "    \n",
    "        elif noise_type == \"salt_pepper\":\n",
    "            s_vs_p = 0.5\n",
    "            amount = self.amount\n",
    "            out = np.copy(img)\n",
    "    \n",
    "            # Salt mode\n",
    "            num_salt = np.ceil(amount * img.size * s_vs_p)\n",
    "            coords = [np.random.randint(0, i, int(num_salt)) for i in img.shape]\n",
    "            out[tuple(coords)] = 255\n",
    "    \n",
    "            # Pepper mode\n",
    "            num_pepper = np.ceil(amount * img.size * (1.0 - s_vs_p))\n",
    "            coords = [np.random.randint(0, i, int(num_pepper)) for i in img.shape]\n",
    "            out[tuple(coords)] = 0\n",
    "    \n",
    "            return out, lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo os caminhos para cada conjunto\n",
    "dir_dataset = \"data\\CamVid\"\n",
    "\n",
    "class_dict = os.path.join(dir_dataset, 'class_dict.csv')\n",
    "df_labels = pd.read_csv(class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para remover todos subdiretórios e arquivos de um diretório\n",
    "def remove_all_files_from_dir(dir_path):\n",
    "    for item in os.listdir(dir_path):\n",
    "        item_path = os.path.join(dir_path, item)\n",
    "        if os.path.isfile(item_path):\n",
    "            os.remove(item_path)\n",
    "        elif os.path.isdir(item_path):\n",
    "            shutil.rmtree(item_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_all_files_from_dir(\"debug_processed_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Parâmetros\n",
    "partition = 4  # Reduzir o tamanho da imagem por um fator de 4\n",
    "prob_train = 0.25  # Probabilidade de aplicar transformações no conjunto de treino\n",
    "prob_others = 0.10  # Probabilidade de aplicar transformações nos conjuntos de validação e teste\n",
    "dir_new_dataset = \"debug_processed_data\"  # Diretório onde os conjuntos processados serão salvos\n",
    "with_brightness_contrast = True  # Aplicar transformações de brilho e contraste\n",
    "var_gaussian = 20  # Variância do ruído gaussiano\n",
    "amount = 0.02  # Quantidade de ruído sal e pimenta\n",
    "\n",
    "# Criando o dataset para o conjunto de treino\n",
    "train_dataset = PreprocessDataset(\n",
    "    dir_dataset=dir_dataset,\n",
    "    df_labels=df_labels,\n",
    "    dir_new_dataset=dir_new_dataset,\n",
    "    set_type='train',  # Carrega o conjunto de treino\n",
    "    partition=partition  # Reduzir a imagem por um fator de 4\n",
    ")\n",
    "\n",
    "# Criando o dataset para o conjunto de validação\n",
    "val_dataset = PreprocessDataset(\n",
    "    dir_dataset=dir_dataset,\n",
    "    df_labels=df_labels,\n",
    "    dir_new_dataset=dir_new_dataset,\n",
    "    set_type='val',  # Carrega o conjunto de validação\n",
    "    partition=partition\n",
    ")\n",
    "\n",
    "# Criando o dataset para o conjunto de teste\n",
    "test_dataset = PreprocessDataset(\n",
    "    dir_dataset=dir_dataset,\n",
    "    df_labels=df_labels,\n",
    "    dir_new_dataset=dir_new_dataset,\n",
    "    set_type='test',  # Carrega o conjunto de teste\n",
    "    partition=partition\n",
    ")\n",
    "\n",
    "# Definindo o tamanho do batch\n",
    "batch_size = 16\n",
    "\n",
    "# Criando o DataLoader para o conjunto de treino\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Criando o DataLoader para o conjunto de validação\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Criando o DataLoader para o conjunto de teste\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Iterando sobre o DataLoader de treino\n",
    "for images, labels in train_loader:\n",
    "    print(f'Batch de imagens: {images.shape}')\n",
    "    print(f'Batch de labels: {labels.shape}')\n",
    "    # Aqui você pode passar as imagens e labels para o seu modelo\n",
    "    break  # Apenas um exemplo, interrompendo após o primeiro batch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
