{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importe pacotes\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importe funções e classes\n",
    "\n",
    "from src.utils import *\n",
    "from src.preprocessdataset import *\n",
    "from src.unet import *\n",
    "from src.unettrainer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\C'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\C'\n",
      "C:\\Users\\Isas_\\AppData\\Local\\Temp\\ipykernel_33392\\1657100305.py:2: SyntaxWarning: invalid escape sequence '\\C'\n",
      "  dir_dataset = \"data\\CamVid\"\n"
     ]
    }
   ],
   "source": [
    "# Definindo os caminhos para cada conjunto\n",
    "dir_dataset = \"data\\CamVid\"\n",
    "\n",
    "class_dict = os.path.join(dir_dataset, 'class_dict.csv')\n",
    "df_labels = pd.read_csv(class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de batches de treino: 21\n",
      "Número de batches de validação: 7\n",
      "Número de batches de teste: 14\n",
      "Batch de imagens: torch.Size([24, 3, 240, 320])\n",
      "Batch de labels: torch.Size([24, 240, 320])\n"
     ]
    }
   ],
   "source": [
    "remove_all_files_from_dir(\"debug_processed_data\")\n",
    "# Parâmetros\n",
    "partition = 3  # Reduzir o tamanho da imagem por um fator de 3\n",
    "prob_train = 0.25  # Probabilidade de aplicar transformações no conjunto de treino\n",
    "prob_others = 0.10  # Probabilidade de aplicar transformações nos conjuntos de validação e teste\n",
    "dir_new_dataset = \"debug_processed_data\"  # Diretório onde os conjuntos processados serão salvos\n",
    "with_brightness_contrast = True  # Aplicar transformações de brilho e contraste\n",
    "var_gaussian = 20  # Variância do ruído gaussiano\n",
    "amount = 0.02  # Quantidade de ruído sal e pimenta\n",
    "\n",
    "# Criando o dataset para o conjunto de treino\n",
    "train_dataset = PreprocessDataset(\n",
    "    dir_dataset=dir_dataset,\n",
    "    df_labels=df_labels,\n",
    "    dir_new_dataset=dir_new_dataset,\n",
    "    set_type='train',  # Carrega o conjunto de treino\n",
    "    partition=partition  # Reduzir a imagem por um fator de 4\n",
    ")\n",
    "\n",
    "# Criando o dataset para o conjunto de validação\n",
    "val_dataset = PreprocessDataset(\n",
    "    dir_dataset=dir_dataset,\n",
    "    df_labels=df_labels,\n",
    "    dir_new_dataset=dir_new_dataset,\n",
    "    set_type='val',  # Carrega o conjunto de validação\n",
    "    partition=partition\n",
    ")\n",
    "\n",
    "# Criando o dataset para o conjunto de teste\n",
    "test_dataset = PreprocessDataset(\n",
    "    dir_dataset=dir_dataset,\n",
    "    df_labels=df_labels,\n",
    "    dir_new_dataset=dir_new_dataset,\n",
    "    set_type='test',  # Carrega o conjunto de teste\n",
    "    partition=partition\n",
    ")\n",
    "\n",
    "# Definindo o tamanho do batch\n",
    "batch_size = 24\n",
    "\n",
    "# Criando o DataLoader para o conjunto de treino\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Criando o DataLoader para o conjunto de validação\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Criando o DataLoader para o conjunto de teste\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f'Número de batches de treino: {len(train_loader)}')\n",
    "print(f'Número de batches de validação: {len(val_loader)}')\n",
    "print(f'Número de batches de teste: {len(test_loader)}')\n",
    "\n",
    "# Iterando sobre o DataLoader de treino\n",
    "for images, labels in train_loader:\n",
    "    print(f'Batch de imagens: {images.shape}')\n",
    "    print(f'Batch de labels: {labels.shape}')\n",
    "    # Aqui você pode passar as imagens e labels para o seu modelo\n",
    "    break  # Apenas um exemplo, interrompendo após o primeiro batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispositivo: cuda\n",
      "Imagens e rótulos movidos para o dispositivo.\n",
      "torch.Size([24, 3, 240, 320])\n",
      "torch.Size([24, 240, 320])\n",
      "Iniciando forward pass...\n",
      "Imagens: torch.Size([24, 3, 240, 320])\n",
      "Labels: torch.Size([24, 240, 320])\n",
      "Saída do modelo: torch.Size([24, 32, 240, 320])\n"
     ]
    }
   ],
   "source": [
    "# Instanciando o modelo U-Net com as dimensões das imagens\n",
    "model = UNet(image_dim=(3, 240, 320), n_channels=64, n_classes=32, depth=5, conv_kernel_size=3, conv_stride=1, conv_padding=1, pool_kernel_size=2, pool_stride=2, pool_padding=0, transpose_kernel_size=3, transpose_stride=2, transpose_padding=1)\n",
    "# Configurando o dispositivo (GPU, se disponível)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Dispositivo: {device}\")\n",
    "model = model.to(device)  # Mover o modelo para o dispositivo\n",
    "\n",
    "# Testando com um batch de dados do DataLoader\n",
    "for images, labels in train_loader:\n",
    "    # Move os dados para o dispositivo (GPU/CPU)\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    print(\"Imagens e rótulos movidos para o dispositivo.\")\n",
    "    print(images.shape)\n",
    "    print(labels.shape)\n",
    "    print(\"Iniciando forward pass...\")\n",
    "    # Passa as imagens pelo modelo U-Net\n",
    "    output = model(images)\n",
    "    \n",
    "    # Exibe as dimensões das imagens, labels e da saída do modelo\n",
    "    print(f\"Imagens: {images.shape}\")\n",
    "    print(f\"Labels: {labels.shape}\")\n",
    "    print(f\"Saída do modelo: {output.shape}\")\n",
    "    \n",
    "    # Quebrar após o primeiro batch, apenas para teste\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispositivo em uso: cuda\n",
      "Criando o modelo U-Net...\n",
      "Modelo U-Net criado.\n",
      "Iniciando treinamento...\n",
      "Número de batches de treino: 32\n",
      "Gerando os dicionários de mapeamento...\n",
      "Criando o DataLoader de treino...\n",
      "Iniciando treinamento...\n"
     ]
    }
   ],
   "source": [
    "# Exemplo de uso\n",
    "image_dim = (3, 240, 320)\n",
    "n_channels = 64\n",
    "n_classes = 32\n",
    "\n",
    "# Verificar se a GPU está disponível e usar o dispositivo adequado\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Dispositivo em uso: {device}\")\n",
    "\n",
    "print(\"Criando o modelo U-Net...\")\n",
    "# Definir o modelo\n",
    "model = UNet(image_dim=image_dim, n_channels=n_channels, n_classes=n_classes)\n",
    "print(\"Modelo U-Net criado.\")\n",
    "\n",
    "\n",
    "# Função de perda e otimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(\"Iniciando treinamento...\")\n",
    "# Carregar os DataLoaders (substitua pelos seus datasets reais)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "print(f'Número de batches de treino: {len(train_loader)}')\n",
    "# Carregar o dicionário de classes\n",
    "dir_dataset = \"data/CamVid\"  # Verifique o caminho correto para seu dataset\n",
    "class_dict_path = os.path.join(dir_dataset, 'class_dict.csv')\n",
    "class_dict = pd.read_csv(class_dict_path)\n",
    "\n",
    "print(\"Gerando os dicionários de mapeamento...\")\n",
    "# Gerar os dicionários de mapeamento\n",
    "rgb_to_index, index_to_label = dict_labels(class_dict)\n",
    "\n",
    "print(\"Criando o DataLoader de treino...\")\n",
    "# Instanciar a classe de treinamento\n",
    "trainer = UNetTrainer(model, train_loader, val_loader, test_loader, rgb_to_index, index_to_label, optimizer, criterion, device=device)\n",
    "\n",
    "print(\"Iniciando treinamento...\")\n",
    "# Treinar o modelo por 25 épocas\n",
    "trainer.train(num_epochs=25)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
