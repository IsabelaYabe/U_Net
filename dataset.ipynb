{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importe pacotes\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importe funções e classes\n",
    "\n",
    "from src.utils import *\n",
    "from src.preprocessdataset import *\n",
    "from src.unet import *\n",
    "from src.unettrainer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\C'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\C'\n",
      "C:\\Users\\Isas_\\AppData\\Local\\Temp\\ipykernel_32284\\1657100305.py:2: SyntaxWarning: invalid escape sequence '\\C'\n",
      "  dir_dataset = \"data\\CamVid\"\n"
     ]
    }
   ],
   "source": [
    "# Definindo os caminhos para cada conjunto\n",
    "dir_dataset = \"data\\CamVid\"\n",
    "\n",
    "class_dict = os.path.join(dir_dataset, 'class_dict.csv')\n",
    "df_labels = pd.read_csv(class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] O sistema não pode encontrar o caminho especificado: 'debug_processed_data_dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mremove_all_files_from_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdebug_processed_data_dataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Parâmetros\u001b[39;00m\n\u001b[0;32m      3\u001b[0m partition \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m  \u001b[38;5;66;03m# Reduzir o tamanho da imagem por um fator de 3\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Isas_\\.vscode\\U_Net\\src\\utils.py:15\u001b[0m, in \u001b[0;36mremove_all_files_from_dir\u001b[1;34m(dir_path)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mremove_all_files_from_dir\u001b[39m(dir_path):\n\u001b[1;32m---> 15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdir_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     16\u001b[0m         item_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dir_path, item)\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(item_path):\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] O sistema não pode encontrar o caminho especificado: 'debug_processed_data_dataset'"
     ]
    }
   ],
   "source": [
    "#remove_all_files_from_dir(\"debug_processed_data_dataset\")\n",
    "# Parâmetros\n",
    "partition = 3  # Reduzir o tamanho da imagem por um fator de 3\n",
    "prob_train = 0.25  # Probabilidade de aplicar transformações no conjunto de treino\n",
    "prob_others = 0.10  # Probabilidade de aplicar transformações nos conjuntos de validação e teste\n",
    "dir_new_dataset = \"debug_processed_data_dataset\"  # Diretório onde os conjuntos processados serão salvos\n",
    "with_brightness_contrast = True  # Aplicar transformações de brilho e contraste\n",
    "var_gaussian = 20  # Variância do ruído gaussiano\n",
    "amount = 0.04  # Quantidade de ruído sal e pimenta\n",
    "\n",
    "# Criando o dataset para o conjunto de treino\n",
    "train_dataset = PreprocessDataset(\n",
    "    dir_dataset=dir_dataset,\n",
    "    df_labels=df_labels,\n",
    "    dir_new_dataset=dir_new_dataset,\n",
    "    set_type='train',  # Carrega o conjunto de treino\n",
    "    partition=partition  # Reduzir a imagem por um fator de 4\n",
    ")\n",
    "\n",
    "# Criando o dataset para o conjunto de validação\n",
    "val_dataset = PreprocessDataset(\n",
    "    dir_dataset=dir_dataset,\n",
    "    df_labels=df_labels,\n",
    "    dir_new_dataset=dir_new_dataset,\n",
    "    set_type='val',  # Carrega o conjunto de validação\n",
    "    partition=partition\n",
    ")\n",
    "\n",
    "# Criando o dataset para o conjunto de teste\n",
    "test_dataset = PreprocessDataset(\n",
    "    dir_dataset=dir_dataset,\n",
    "    df_labels=df_labels,\n",
    "    dir_new_dataset=dir_new_dataset,\n",
    "    set_type='test',  # Carrega o conjunto de teste\n",
    "    partition=partition\n",
    ")\n",
    "\n",
    "# Definindo o tamanho do batch\n",
    "batch_size = 24\n",
    "\n",
    "# Criando o DataLoader para o conjunto de treino\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Criando o DataLoader para o conjunto de validação\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Criando o DataLoader para o conjunto de teste\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f'Número de batches de treino: {len(train_loader)}')\n",
    "print(f'Número de batches de validação: {len(val_loader)}')\n",
    "print(f'Número de batches de teste: {len(test_loader)}')\n",
    "\n",
    "# Iterando sobre o DataLoader de treino\n",
    "for images, labels in train_loader:\n",
    "    print(f'Batch de imagens: {images.shape}')\n",
    "    print(f'Batch de labels: {labels.shape}')\n",
    "    # Aqui você pode passar as imagens e labels para o seu modelo\n",
    "    break  # Apenas um exemplo, interrompendo após o primeiro batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispositivo: cuda\n",
      "Imagens e rótulos movidos para o dispositivo.\n",
      "torch.Size([24, 3, 240, 320])\n",
      "torch.Size([24, 240, 320])\n",
      "Iniciando forward pass...\n",
      "Imagens: torch.Size([24, 3, 240, 320])\n",
      "Labels: torch.Size([24, 240, 320])\n",
      "Saída do modelo: torch.Size([24, 32, 240, 320])\n"
     ]
    }
   ],
   "source": [
    "# Instanciando o modelo U-Net com as dimensões das imagens\n",
    "model = UNet(image_dim=(3, 240, 320), n_channels=64, n_classes=32, depth=5, conv_kernel_size=3, conv_stride=1, conv_padding=1, pool_kernel_size=2, pool_stride=2, pool_padding=0, transpose_kernel_size=3, transpose_stride=2, transpose_padding=1)\n",
    "# Configurando o dispositivo (GPU, se disponível)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Dispositivo: {device}\")\n",
    "model = model.to(device)  # Mover o modelo para o dispositivo\n",
    "\n",
    "# Testando com um batch de dados do DataLoader\n",
    "for images, labels in train_loader:\n",
    "    # Move os dados para o dispositivo (GPU/CPU)\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    print(\"Imagens e rótulos movidos para o dispositivo.\")\n",
    "    print(images.shape)\n",
    "    print(labels.shape)\n",
    "    print(\"Iniciando forward pass...\")\n",
    "    # Passa as imagens pelo modelo U-Net\n",
    "    output = model(images)\n",
    "    \n",
    "    # Exibe as dimensões das imagens, labels e da saída do modelo\n",
    "    print(f\"Imagens: {images.shape}\")\n",
    "    print(f\"Labels: {labels.shape}\")\n",
    "    print(f\"Saída do modelo: {output.shape}\")\n",
    "    \n",
    "    # Quebrar após o primeiro batch, apenas para teste\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de uso\n",
    "image_dim = (3, 240, 320)\n",
    "n_channels = 64\n",
    "n_classes = 32\n",
    "\n",
    "# Verificar se a GPU está disponível e usar o dispositivo adequado\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Dispositivo em uso: {device}\")\n",
    "\n",
    "# Definir o modelo\n",
    "model = UNet(image_dim=image_dim, n_channels=n_channels, n_classes=n_classes)\n",
    "\n",
    "# Função de perda e otimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Carregar os DataLoaders (substitua pelos seus datasets reais)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Carregar o dicionário de classes\n",
    "dir_dataset = \"data/CamVid\"  # Verifique o caminho correto para seu dataset\n",
    "class_dict_path = os.path.join(dir_dataset, 'class_dict.csv')\n",
    "class_dict = pd.read_csv(class_dict_path)\n",
    "\n",
    "# Gerar os dicionários de mapeamento\n",
    "rgb_to_index, index_to_label = dict_labels(class_dict)\n",
    "\n",
    "# Instanciar a classe de treinamento\n",
    "trainer = UNetTrainer(model, train_loader, val_loader, test_loader, rgb_to_index, index_to_label, optimizer, criterion, device=device)\n",
    "\n",
    "# Treinar o modelo por 25 épocas\n",
    "trainer.train(num_epochs=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainer.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir testamos umdataset menor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_all_files_from_dir(\"debug_processed_data_dataset\")\n",
    "# Parâmetros\n",
    "partition = 3  # Reduzir o tamanho da imagem por um fator de 3\n",
    "prob_train = 0  # Probabilidade de aplicar transformações no conjunto de treino\n",
    "prob_others = 0  # Probabilidade de aplicar transformações nos conjuntos de validação e teste\n",
    "dir_new_dataset = \"debug_processed_data_dataset\"  # Diretório onde os conjuntos processados serão salvos\n",
    "with_brightness_contrast = True  # Aplicar transformações de brilho e contraste\n",
    "var_gaussian = 20  # Variância do ruído gaussiano\n",
    "amount = 0.04  # Quantidade de ruído sal e pimenta\n",
    "\n",
    "# Criando o dataset para o conjunto de treino\n",
    "train_dataset = PreprocessDataset(\n",
    "    dir_dataset=dir_dataset,\n",
    "    df_labels=df_labels,\n",
    "    dir_new_dataset=dir_new_dataset,\n",
    "    set_type='train',  # Carrega o conjunto de treino\n",
    "    partition=partition  # Reduzir a imagem por um fator de 4\n",
    ")\n",
    "\n",
    "# Criando o dataset para o conjunto de validação\n",
    "val_dataset = PreprocessDataset(\n",
    "    dir_dataset=dir_dataset,\n",
    "    df_labels=df_labels,\n",
    "    dir_new_dataset=dir_new_dataset,\n",
    "    set_type='val',  # Carrega o conjunto de validação\n",
    "    partition=partition\n",
    ")\n",
    "\n",
    "# Criando o dataset para o conjunto de teste\n",
    "test_dataset = PreprocessDataset(\n",
    "    dir_dataset=dir_dataset,\n",
    "    df_labels=df_labels,\n",
    "    dir_new_dataset=dir_new_dataset,\n",
    "    set_type='test',  # Carrega o conjunto de teste\n",
    "    partition=partition\n",
    ")\n",
    "\n",
    "# Definindo o tamanho do batch\n",
    "batch_size = 24\n",
    "\n",
    "# Criando o DataLoader para o conjunto de treino\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Criando o DataLoader para o conjunto de validação\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Criando o DataLoader para o conjunto de teste\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f'Número de batches de treino: {len(train_loader)}')\n",
    "print(f'Número de batches de validação: {len(val_loader)}')\n",
    "print(f'Número de batches de teste: {len(test_loader)}')\n",
    "\n",
    "# Iterando sobre o DataLoader de treino\n",
    "for images, labels in train_loader:\n",
    "    print(f'Batch de imagens: {images.shape}')\n",
    "    print(f'Batch de labels: {labels.shape}')\n",
    "    # Aqui você pode passar as imagens e labels para o seu modelo\n",
    "    break  # Apenas um exemplo, interrompendo após o primeiro batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciando o modelo U-Net com as dimensões das imagens\n",
    "model = UNet(image_dim=(3, 240, 320), n_channels=64, n_classes=32, depth=5, conv_kernel_size=3, conv_stride=1, conv_padding=1, pool_kernel_size=2, pool_stride=2, pool_padding=0, transpose_kernel_size=3, transpose_stride=2, transpose_padding=1)\n",
    "# Configurando o dispositivo (GPU, se disponível)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Dispositivo: {device}\")\n",
    "model = model.to(device)  # Mover o modelo para o dispositivo\n",
    "\n",
    "# Testando com um batch de dados do DataLoader\n",
    "for images, labels in train_loader:\n",
    "    # Move os dados para o dispositivo (GPU/CPU)\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    print(\"Imagens e rótulos movidos para o dispositivo.\")\n",
    "    print(images.shape)\n",
    "    print(labels.shape)\n",
    "    print(\"Iniciando forward pass...\")\n",
    "    # Passa as imagens pelo modelo U-Net\n",
    "    output = model(images)\n",
    "    \n",
    "    # Exibe as dimensões das imagens, labels e da saída do modelo\n",
    "    print(f\"Imagens: {images.shape}\")\n",
    "    print(f\"Labels: {labels.shape}\")\n",
    "    print(f\"Saída do modelo: {output.shape}\")\n",
    "    \n",
    "    # Quebrar após o primeiro batch, apenas para teste\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de uso\n",
    "image_dim = (3, 240, 320)\n",
    "n_channels = 64\n",
    "n_classes = 32\n",
    "\n",
    "# Verificar se a GPU está disponível e usar o dispositivo adequado\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Dispositivo em uso: {device}\")\n",
    "\n",
    "# Definir o modelo\n",
    "model = UNet(image_dim=image_dim, n_channels=n_channels, n_classes=n_classes)\n",
    "\n",
    "# Função de perda e otimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Carregar os DataLoaders (substitua pelos seus datasets reais)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Carregar o dicionário de classes\n",
    "dir_dataset = \"data/CamVid\"  # Verifique o caminho correto para seu dataset\n",
    "class_dict_path = os.path.join(dir_dataset, 'class_dict.csv')\n",
    "class_dict = pd.read_csv(class_dict_path)\n",
    "\n",
    "# Gerar os dicionários de mapeamento\n",
    "rgb_to_index, index_to_label = dict_labels(class_dict)\n",
    "\n",
    "# Instanciar a classe de treinamento\n",
    "trainer = UNetTrainer(model, train_loader, val_loader, test_loader, rgb_to_index, index_to_label, optimizer, criterion, device=device)\n",
    "\n",
    "# Treinar o modelo por 25 épocas\n",
    "trainer.train(num_epochs=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainer.history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
